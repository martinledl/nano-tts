{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T15:34:44.506279Z",
     "start_time": "2026-02-02T15:34:44.493171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "e6a77c9b5647eb31",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T15:34:45.209392Z",
     "start_time": "2026-02-02T15:34:44.510952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from src.utils import *"
   ],
   "id": "4d84ae60adb636f4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T15:34:45.368572Z",
     "start_time": "2026-02-02T15:34:45.361136Z"
    }
   },
   "cell_type": "code",
   "source": "os.chdir('..')",
   "id": "147295388d94ae8f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T15:34:45.451676Z",
     "start_time": "2026-02-02T15:34:45.373619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "\n",
    "with open(get_config_path(\"data_config.yaml\"), \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ],
   "id": "9ae05b6c9adc3fd1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T15:34:45.466198Z",
     "start_time": "2026-02-02T15:34:45.457237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def seconds_to_frames(seconds, sample_rate=config[\"sample_rate\"], hop_length=config[\"hop_length\"]):\n",
    "    frames = int(seconds * sample_rate / hop_length)\n",
    "    return frames"
   ],
   "id": "1fde7a0af2534c5f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T15:34:45.478957Z",
     "start_time": "2026-02-02T15:34:45.471309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# symbols = {}\n",
    "# for filepath in os.listdir(get_alignment_dir()):\n",
    "#     if not filepath.endswith(\".TextGrid\"):\n",
    "#         continue\n",
    "#     alignment = get_alignment_path(filepath)\n",
    "#     with open(alignment, \"r\") as f:\n",
    "#         lines = f.readlines()\n",
    "#         \n",
    "#     found_phones = False\n",
    "#     for i, line in enumerate(lines):\n",
    "#         if 'item [2]:' in line:\n",
    "#             found_phones = True\n",
    "#         if found_phones and 'text =' in line:\n",
    "#             phone = line.split('=')[1].strip().strip('\"')\n",
    "#             if phone not in symbols:\n",
    "#                 symbols[phone] = len(symbols)\n",
    "#                 \n",
    "# symbols[\"<pad>\"] = len(symbols)"
   ],
   "id": "c27a01fb178288c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T15:34:59.186144Z",
     "start_time": "2026-02-02T15:34:45.484787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scripts.prepare_dataset import get_mel_spectrogram\n",
    "\n",
    "example_wav = get_audio_path(\"LJ001-0001.wav\")\n",
    "mel_spectrogram = get_mel_spectrogram(example_wav, config)\n",
    "mel_spectrogram.shape"
   ],
   "id": "4c084d99c2f911dd",
   "outputs": [
    {
     "ename": "LibsndfileError",
     "evalue": "Error opening '/Users/martinledl/Developer/nano-tts/data/LJSpeech-1.1/wavs/LJ001-0001.wav': System error.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mLibsndfileError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mscripts\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprepare_dataset\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_mel_spectrogram\n\u001B[1;32m      3\u001B[0m example_wav \u001B[38;5;241m=\u001B[39m get_audio_path(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLJ001-0001.wav\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m mel_spectrogram \u001B[38;5;241m=\u001B[39m \u001B[43mget_mel_spectrogram\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexample_wav\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m mel_spectrogram\u001B[38;5;241m.\u001B[39mshape\n",
      "File \u001B[0;32m~/Developer/nano-tts/scripts/prepare_dataset.py:28\u001B[0m, in \u001B[0;36mget_mel_spectrogram\u001B[0;34m(audio_path, config)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;124;03mComputes Mel Spectrogram using SpeechBrain implementation to match HiFi-GAN.\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;124;03mReturns: Tensor of shape [Mels, Time]\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Load Audio\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# torchaudio loads as [channels, time]\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m wav, sr \u001B[38;5;241m=\u001B[39m \u001B[43mtorchaudio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43maudio_path\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# Resample if needed\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sr \u001B[38;5;241m!=\u001B[39m config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msample_rate\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m~/Developer/ml-venv/lib/python3.11/site-packages/torchaudio/_backend/utils.py:205\u001B[0m, in \u001B[0;36mget_load_func.<locals>.load\u001B[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Load audio data from source.\u001B[39;00m\n\u001B[1;32m    129\u001B[0m \n\u001B[1;32m    130\u001B[0m \u001B[38;5;124;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;124;03m        `[channel, time]` else `[time, channel]`.\u001B[39;00m\n\u001B[1;32m    203\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    204\u001B[0m backend \u001B[38;5;241m=\u001B[39m dispatcher(uri, \u001B[38;5;28mformat\u001B[39m, backend)\n\u001B[0;32m--> 205\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43muri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_frames\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchannels_first\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/ml-venv/lib/python3.11/site-packages/torchaudio/_backend/soundfile.py:27\u001B[0m, in \u001B[0;36mSoundfileBackend.load\u001B[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mload\u001B[39m(\n\u001B[1;32m     19\u001B[0m     uri: Union[BinaryIO, \u001B[38;5;28mstr\u001B[39m, os\u001B[38;5;241m.\u001B[39mPathLike],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     25\u001B[0m     buffer_size: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m4096\u001B[39m,\n\u001B[1;32m     26\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor, \u001B[38;5;28mint\u001B[39m]:\n\u001B[0;32m---> 27\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msoundfile_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43muri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_frames\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchannels_first\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/ml-venv/lib/python3.11/site-packages/torchaudio/_backend/soundfile_backend.py:221\u001B[0m, in \u001B[0;36mload\u001B[0;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;129m@_requires_soundfile\u001B[39m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mload\u001B[39m(\n\u001B[1;32m    141\u001B[0m     filepath: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;28mformat\u001B[39m: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    147\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor, \u001B[38;5;28mint\u001B[39m]:\n\u001B[1;32m    148\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load audio data from file.\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \n\u001B[1;32m    150\u001B[0m \u001B[38;5;124;03m    Note:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;124;03m            `[channel, time]` else `[time, channel]`.\u001B[39;00m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 221\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43msoundfile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSoundFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m file_:\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m file_\u001B[38;5;241m.\u001B[39mformat \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWAV\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m normalize:\n\u001B[1;32m    223\u001B[0m             dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfloat32\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/Developer/ml-venv/lib/python3.11/site-packages/soundfile.py:690\u001B[0m, in \u001B[0;36mSoundFile.__init__\u001B[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001B[0m\n\u001B[1;32m    687\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bitrate_mode \u001B[38;5;241m=\u001B[39m bitrate_mode\n\u001B[1;32m    688\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info \u001B[38;5;241m=\u001B[39m _create_info_struct(file, mode, samplerate, channels,\n\u001B[1;32m    689\u001B[0m                                  \u001B[38;5;28mformat\u001B[39m, subtype, endian)\n\u001B[0;32m--> 690\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode_int\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosefd\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mset\u001B[39m(mode)\u001B[38;5;241m.\u001B[39missuperset(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr+\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseekable():\n\u001B[1;32m    692\u001B[0m     \u001B[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001B[39;00m\n\u001B[1;32m    693\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseek(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/Developer/ml-venv/lib/python3.11/site-packages/soundfile.py:1265\u001B[0m, in \u001B[0;36mSoundFile._open\u001B[0;34m(self, file, mode_int, closefd)\u001B[0m\n\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file_ptr \u001B[38;5;241m==\u001B[39m _ffi\u001B[38;5;241m.\u001B[39mNULL:\n\u001B[1;32m   1263\u001B[0m     \u001B[38;5;66;03m# get the actual error code\u001B[39;00m\n\u001B[1;32m   1264\u001B[0m     err \u001B[38;5;241m=\u001B[39m _snd\u001B[38;5;241m.\u001B[39msf_error(file_ptr)\n\u001B[0;32m-> 1265\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m LibsndfileError(err, prefix\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError opening \u001B[39m\u001B[38;5;132;01m{0!r}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname))\n\u001B[1;32m   1266\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode_int \u001B[38;5;241m==\u001B[39m _snd\u001B[38;5;241m.\u001B[39mSFM_WRITE:\n\u001B[1;32m   1267\u001B[0m     \u001B[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001B[39;00m\n\u001B[1;32m   1268\u001B[0m     \u001B[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001B[39;00m\n\u001B[1;32m   1269\u001B[0m     \u001B[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001B[39;00m\n\u001B[1;32m   1270\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info\u001B[38;5;241m.\u001B[39mframes \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[0;31mLibsndfileError\u001B[0m: Error opening '/Users/martinledl/Developer/nano-tts/data/LJSpeech-1.1/wavs/LJ001-0001.wav': System error."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martinledl/Developer/ml-venv/lib/python3.11/site-packages/IPython/extensions/autoreload.py:211: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if not hasattr(module, \"__file__\") or module.__file__ is None:\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T15:34:59.246573Z",
     "start_time": "2026-02-01T22:05:38.481842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchaudio\n",
    "from speechbrain.inference.vocoders import HIFIGAN\n",
    "from speechbrain.lobes.models.FastSpeech2 import mel_spectogram\n",
    "\n",
    "# Load a pretrained HIFIGAN Vocoder\n",
    "hifi_gan = HIFIGAN.from_hparams(source=\"speechbrain/tts-hifigan-ljspeech\", savedir=\"pretrained_models/tts-hifigan-ljspeech\")\n",
    "\n",
    "# Compute the mel spectrogram.\n",
    "# IMPORTANT: Use these specific parameters to match the Vocoder's training settings for optimal results.\n",
    "spectrogram = get_mel_spectrogram(example_wav, config)\n",
    "\n",
    "# Convert the spectrogram to waveform\n",
    "waveforms = hifi_gan.decode_batch(spectrogram)\n",
    "\n",
    "# Save the reconstructed audio as a waveform\n",
    "# torchaudio.save('waveform_reconstructed.wav', waveforms.squeeze(1), 22050)\n"
   ],
   "id": "f4d2712dcafed9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martinledl/Developer/ml-venv/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T15:48:41.976831Z",
     "start_time": "2026-02-02T15:48:41.921711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "data = torch.load('data/processed/LJ001-0001.pt')\n",
    "data['phonemes'].shape, data['durations'].shape, data['mel_spectrogram'].shape"
   ],
   "id": "91e75ce6287a878c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([114]), torch.Size([114]), torch.Size([80, 832]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b400023b4cde3127"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
